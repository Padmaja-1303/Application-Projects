{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e3faa7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "from keras.models import Model\n",
    "import timeit\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a0a4f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 2\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd9f8381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 8)         80        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 11, 11, 16)        1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 16)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 5, 5, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                12832     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 14,410\n",
      "Trainable params: 14,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(8, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(16, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59812093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 9s 155us/step - loss: 0.3240 - accuracy: 0.8975 - val_loss: 0.0940 - val_accuracy: 0.9698\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 8s 141us/step - loss: 0.2883 - accuracy: 0.9096 - val_loss: 0.0803 - val_accuracy: 0.9747\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1d317fe4c88>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ad375be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pylab as plt\n",
    "\n",
    "plt.imshow(x_test[130:131].reshape(28,28),cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05bd3160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Score:\n",
      " [0.11495801 0.10586023 0.08930805 0.11774953 0.11181092 0.10724964\n",
      " 0.06807563 0.10167866 0.08692681 0.09638242]\n",
      "\n",
      "Thresholded Score:\n",
      " [0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11400/4094883239.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mthresholded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\nThresholded Score:\\n'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mthresholded\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\nPredicted Digit:\\n'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthresholded\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "prediction = model.predict(x_test[130:131])\n",
    "print('Prediction Score:\\n',prediction[0])\n",
    "thresholded = (prediction>0.5)*1\n",
    "print('\\nThresholded Score:\\n',thresholded[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc592a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mobilenet_0.25_224\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)    (None, 225, 225, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 112, 112, 8)       216       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, 112, 112, 8)       32        \n",
      "_________________________________________________________________\n",
      "conv1_relu (ReLU)            (None, 112, 112, 8)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, 112, 112, 8)       72        \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, 112, 112, 8)       32        \n",
      "_________________________________________________________________\n",
      "conv_dw_1_relu (ReLU)        (None, 112, 112, 8)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, 112, 112, 16)      128       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, 112, 112, 16)      64        \n",
      "_________________________________________________________________\n",
      "conv_pw_1_relu (ReLU)        (None, 112, 112, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv_pad_2 (ZeroPadding2D)   (None, 113, 113, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, 56, 56, 16)        144       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, 56, 56, 16)        64        \n",
      "_________________________________________________________________\n",
      "conv_dw_2_relu (ReLU)        (None, 56, 56, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, 56, 56, 32)        512       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, 56, 56, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_relu (ReLU)        (None, 56, 56, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, 56, 56, 32)        288       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, 56, 56, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_relu (ReLU)        (None, 56, 56, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, 56, 56, 32)        1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, 56, 56, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv_pw_3_relu (ReLU)        (None, 56, 56, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_pad_4 (ZeroPadding2D)   (None, 57, 57, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, 28, 28, 32)        288       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_relu (ReLU)        (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, 28, 28, 64)        2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_pw_4_relu (ReLU)        (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, 28, 28, 64)        576       \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_dw_5_relu (ReLU)        (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, 28, 28, 64)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_pw_5_relu (ReLU)        (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pad_6 (ZeroPadding2D)   (None, 29, 29, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, 14, 14, 64)        576       \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_dw_6_relu (ReLU)        (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, 14, 14, 128)       8192      \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_6_relu (ReLU)        (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)  (None, 14, 14, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormaliza (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_7_relu (ReLU)        (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_7 (Conv2D)           (None, 14, 14, 128)       16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormaliza (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_7_relu (ReLU)        (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)  (None, 14, 14, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormaliza (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_8_relu (ReLU)        (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_8 (Conv2D)           (None, 14, 14, 128)       16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormaliza (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_8_relu (ReLU)        (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)  (None, 14, 14, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormaliza (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_9_relu (ReLU)        (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_9 (Conv2D)           (None, 14, 14, 128)       16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormaliza (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_9_relu (ReLU)        (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D) (None, 14, 14, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormaliz (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_10_relu (ReLU)       (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_10 (Conv2D)          (None, 14, 14, 128)       16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormaliz (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_10_relu (ReLU)       (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D) (None, 14, 14, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormaliz (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_11_relu (ReLU)       (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_11 (Conv2D)          (None, 14, 14, 128)       16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormaliz (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_11_relu (ReLU)       (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_12 (ZeroPadding2D)  (None, 15, 15, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D) (None, 7, 7, 128)         1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormaliz (None, 7, 7, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv_dw_12_relu (ReLU)       (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_12 (Conv2D)          (None, 7, 7, 256)         32768     \n",
      "_________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormaliz (None, 7, 7, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_12_relu (ReLU)       (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D) (None, 7, 7, 256)         2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormaliz (None, 7, 7, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_relu (ReLU)       (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_13 (Conv2D)          (None, 7, 7, 256)         65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormaliz (None, 7, 7, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_13_relu (ReLU)       (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv_preds (Conv2D)          (None, 1, 1, 1000)        257000    \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "act_softmax (Activation)     (None, 1000)              0         \n",
      "=================================================================\n",
      "Total params: 475,544\n",
      "Trainable params: 470,072\n",
      "Non-trainable params: 5,472\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = MobileNet(input_shape=None, alpha=0.25, depth_multiplier=1, dropout=1e-3, \n",
    "                                 include_top=True, weights='imagenet', input_tensor=None, pooling=None, classes=1000)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a4237a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:\n",
      " [[('n04238763', 'slide_rule', 0.16747911), ('n04118776', 'rule', 0.094237275), ('n06359193', 'web_site', 0.08934647), ('n03291819', 'envelope', 0.08290967), ('n07565083', 'menu', 0.045008305)]]\n"
     ]
    }
   ],
   "source": [
    "# Write the image name below\n",
    "\n",
    "img_path = 'C:/Accuracy.png'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "preds = model.predict(x)\n",
    "print('Predicted:\\n', decode_predictions(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b163a1a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Shape:\n",
      " (1, 1000)\n",
      "\n",
      "Features:\n",
      " [[6.39265139e-08 3.00671061e-04 9.20843377e-07 3.52909638e-07\n",
      "  1.13535066e-06 7.99440841e-07 5.50967449e-08 2.96489873e-07\n",
      "  4.90671006e-08 4.05123359e-07 7.98039945e-09 8.26358146e-08\n",
      "  5.19447610e-07 1.49442538e-08 3.70590598e-08 1.63414109e-06\n",
      "  6.38625295e-08 2.90876017e-08 7.95098885e-08 2.50605918e-08\n",
      "  4.80904117e-09 1.33857839e-07 5.00358647e-06 2.16308862e-07\n",
      "  1.46179923e-06 1.98795025e-08 5.08573203e-06 5.63040434e-04\n",
      "  2.95293688e-07 2.67502605e-06 9.83652049e-10 8.62523635e-08\n",
      "  1.34005687e-08 1.42248915e-08 1.84497129e-08 1.98258636e-08\n",
      "  6.96427023e-08 1.06341362e-08 1.39079532e-06 3.88140307e-07\n",
      "  1.79501058e-05 1.94877293e-06 9.22663457e-06 4.67660684e-08\n",
      "  6.46344574e-07 6.01652417e-08 5.98519773e-06 1.03974152e-07\n",
      "  4.48084414e-09 7.24979031e-07 2.38661437e-06 1.35397094e-09\n",
      "  4.79863729e-07 1.74621647e-07 4.34177405e-09 1.53913177e-07\n",
      "  1.21456294e-08 2.69236411e-09 7.86071865e-08 1.05032356e-07\n",
      "  1.99420583e-07 4.37616077e-09 1.73330494e-09 1.26505286e-08\n",
      "  2.06921300e-07 4.32054748e-07 1.18584914e-07 6.07533508e-08\n",
      "  1.54921636e-07 1.09776920e-07 4.13075304e-06 5.51247604e-06\n",
      "  1.35802509e-07 4.33980949e-06 1.43703642e-06 2.30655642e-05\n",
      "  1.60636148e-07 1.75443347e-06 1.13667293e-05 3.98668170e-04\n",
      "  1.94274861e-07 6.90509983e-10 9.59438324e-08 1.43410603e-07\n",
      "  1.72287073e-08 1.79539896e-07 5.07974278e-07 1.15429384e-06\n",
      "  1.10193341e-05 1.34311151e-07 2.09510131e-06 2.04823095e-07\n",
      "  2.42150395e-06 5.01290955e-08 5.04478794e-06 1.01988160e-08\n",
      "  3.46468323e-06 8.22619342e-08 3.08448129e-08 7.12814199e-07\n",
      "  1.19412580e-05 1.88816891e-08 5.63578681e-07 2.42189515e-07\n",
      "  6.88970840e-06 2.42609104e-07 8.02903960e-05 9.08649235e-06\n",
      "  4.07171996e-07 3.01486494e-07 7.49272147e-08 2.21640366e-04\n",
      "  6.29384795e-06 5.93930017e-05 1.17440744e-04 1.49682108e-07\n",
      "  5.68952778e-08 3.70184381e-08 3.14857232e-07 2.21291003e-08\n",
      "  4.71875239e-07 3.92889007e-07 3.55786973e-08 7.38400345e-08\n",
      "  4.14249328e-08 6.36147632e-08 9.54698498e-06 2.53381586e-06\n",
      "  7.35553556e-07 5.42546650e-06 6.81589245e-06 4.85256862e-07\n",
      "  7.74385114e-07 8.37143475e-08 3.49443894e-06 6.97268433e-06\n",
      "  1.08804073e-07 6.21651619e-09 1.55156066e-08 3.15007824e-08\n",
      "  6.25034829e-07 2.45917499e-06 2.18934417e-07 1.35207858e-06\n",
      "  6.93405673e-06 9.80498740e-08 2.34602169e-08 9.52697121e-07\n",
      "  4.49578692e-07 3.36686981e-06 1.70281728e-05 1.42437739e-06\n",
      "  9.83245059e-08 2.80133321e-07 9.09280243e-06 3.41700463e-08\n",
      "  2.20404431e-07 3.37098669e-07 2.75577925e-08 1.72608507e-05\n",
      "  2.48143510e-06 3.07171240e-06 3.33909156e-06 4.35630909e-06\n",
      "  5.75733020e-06 1.90988430e-05 1.79223514e-06 6.94491348e-07\n",
      "  2.81880602e-05 1.53058556e-06 3.83134278e-07 1.04964073e-07\n",
      "  1.76544717e-08 1.09167222e-05 4.27192026e-06 8.97617326e-07\n",
      "  3.78294857e-07 1.83621140e-07 7.27441220e-05 2.02698698e-06\n",
      "  7.43572059e-07 5.98350482e-07 8.31442264e-07 1.91696415e-07\n",
      "  3.37949388e-07 5.64824632e-06 9.39916561e-07 5.27970997e-07\n",
      "  2.38449847e-08 2.84719999e-06 1.75636458e-07 2.39045039e-06\n",
      "  9.59934823e-07 2.59511376e-06 2.15046665e-08 2.24444489e-06\n",
      "  3.36250530e-08 1.09564348e-06 2.21762555e-08 5.86468877e-06\n",
      "  4.18095368e-07 4.21246978e-06 1.83075167e-06 1.67614107e-05\n",
      "  2.53762096e-07 3.55547018e-05 1.73697717e-05 4.63692886e-05\n",
      "  1.94430013e-05 2.02210809e-04 2.97419047e-05 1.15920184e-03\n",
      "  6.05857394e-06 3.11631698e-06 1.18733449e-04 2.16462431e-05\n",
      "  7.60735566e-05 7.39132429e-06 4.54603060e-06 5.77467063e-07\n",
      "  1.86497127e-05 4.46527656e-06 4.33097875e-06 8.15825188e-05\n",
      "  1.08483247e-04 1.04574901e-05 1.14039017e-06 1.11812560e-05\n",
      "  4.30795944e-06 6.79874404e-07 7.64446668e-06 1.30610224e-05\n",
      "  5.24874213e-06 7.53132872e-06 1.76459245e-04 7.77389971e-07\n",
      "  7.96383683e-05 4.50968491e-06 8.39318309e-05 1.43410734e-05\n",
      "  1.71552638e-05 2.96408029e-06 4.35760148e-06 1.16693454e-05\n",
      "  3.20557388e-06 8.78711398e-06 1.95739403e-07 7.61945148e-06\n",
      "  6.11042560e-06 7.46482647e-06 3.85584872e-06 1.25741808e-05\n",
      "  6.47279649e-07 6.58227327e-06 3.86474494e-05 1.17222380e-05\n",
      "  1.29417558e-05 1.25769157e-05 1.67714374e-04 9.25683889e-06\n",
      "  9.56464210e-05 1.24398885e-05 1.44780040e-06 4.65493258e-06\n",
      "  1.08955683e-05 1.38561163e-07 5.93115459e-08 6.71482425e-08\n",
      "  7.29384411e-08 1.11491579e-06 1.77926249e-05 5.38722759e-07\n",
      "  3.71861424e-05 6.51443843e-05 4.20274591e-05 6.29382157e-07\n",
      "  8.57375107e-06 8.12365215e-06 2.31257491e-06 2.00623708e-05\n",
      "  2.34728191e-06 2.37351310e-06 2.86222780e-06 1.73759618e-04\n",
      "  6.73844795e-07 2.57894135e-06 8.56385807e-09 5.79932049e-08\n",
      "  3.21086056e-08 8.43710808e-08 5.27005852e-08 1.21439683e-07\n",
      "  4.15740402e-07 8.52431469e-07 3.05862250e-06 3.32004947e-06\n",
      "  2.58963276e-03 6.41236397e-07 2.73685669e-06 1.15280919e-07\n",
      "  2.86275750e-08 1.42733359e-06 1.54844528e-07 5.87023635e-07\n",
      "  1.01463755e-07 8.89618832e-08 6.06339518e-06 1.32205957e-06\n",
      "  8.95425160e-07 1.81935832e-06 5.90927993e-05 9.17016337e-07\n",
      "  6.15815679e-06 5.53772134e-06 2.23878924e-05 3.91823761e-07\n",
      "  1.50806372e-08 1.69022826e-07 6.24702238e-07 4.22121076e-07\n",
      "  2.41011821e-06 1.88546338e-07 1.35747470e-07 7.36890282e-09\n",
      "  5.01104758e-09 6.25595362e-07 1.66986283e-07 1.54089037e-06\n",
      "  6.43264775e-06 4.12401647e-07 1.38357300e-05 1.41206483e-05\n",
      "  6.52631497e-05 1.04413216e-03 2.81830324e-07 5.31016383e-07\n",
      "  4.50828082e-07 2.68122471e-06 6.00787280e-06 3.01557236e-07\n",
      "  2.48955018e-07 3.51080666e-06 2.34630505e-07 1.46489745e-08\n",
      "  3.66129370e-07 6.92167532e-06 4.67686760e-07 6.54487594e-05\n",
      "  3.59704941e-08 2.16588241e-08 1.79490428e-07 7.19606490e-08\n",
      "  4.54701251e-07 1.69473878e-06 2.40804212e-07 1.46937410e-07\n",
      "  1.50689914e-06 4.00042290e-06 2.73587534e-06 3.25050820e-07\n",
      "  3.93996835e-08 3.95011193e-06 3.87173912e-07 3.95217086e-07\n",
      "  4.50396413e-08 1.26732425e-06 1.04536106e-07 5.09852249e-08\n",
      "  2.20578542e-07 9.38713853e-08 2.85826456e-08 2.55207340e-07\n",
      "  2.89817599e-05 9.42361021e-06 2.70549481e-06 1.91350757e-08\n",
      "  5.31437436e-05 1.58043804e-05 3.31924348e-05 1.73422029e-06\n",
      "  9.31856107e-07 1.03068068e-07 7.27307633e-06 3.29624394e-09\n",
      "  3.52656615e-09 7.57032524e-07 5.43710200e-07 6.51807966e-07\n",
      "  2.73037291e-08 7.04899747e-08 1.58646912e-07 9.20074456e-07\n",
      "  2.65125118e-06 3.56811114e-08 2.92347323e-07 1.14103852e-06\n",
      "  1.46303989e-07 3.60211118e-07 7.13374291e-04 5.00849183e-07\n",
      "  5.72313979e-07 3.16722362e-05 5.51512421e-05 3.98389966e-06\n",
      "  2.11284187e-05 1.44481294e-06 9.85533347e-07 1.47528003e-03\n",
      "  2.38084780e-07 5.37518831e-03 8.39030599e-06 2.90877269e-05\n",
      "  9.80787212e-04 4.81463612e-05 4.54058645e-05 1.82956501e-06\n",
      "  3.20663326e-04 1.95973644e-05 1.89391673e-02 2.09035657e-04\n",
      "  7.25357040e-06 1.28547535e-05 6.90515735e-04 1.18521211e-06\n",
      "  2.61936766e-05 2.47603530e-05 5.24983136e-03 7.08972293e-05\n",
      "  5.11599956e-06 1.41041676e-06 7.11520715e-06 8.28312182e-07\n",
      "  3.88174230e-04 4.43785160e-04 2.27351935e-04 2.73830316e-04\n",
      "  1.08138502e-05 2.72270881e-05 2.29622913e-03 1.27222311e-05\n",
      "  3.73349758e-06 3.05692956e-05 2.68828728e-07 1.19549313e-05\n",
      "  1.70926014e-05 6.39204791e-06 1.08906813e-02 2.67584346e-05\n",
      "  1.01430187e-05 1.01485102e-06 9.00150098e-06 1.74634405e-08\n",
      "  1.17787494e-07 3.09267307e-06 3.24151260e-05 7.32350281e-06\n",
      "  9.90634726e-05 1.42269255e-06 2.74952909e-04 4.21587401e-06\n",
      "  2.80140648e-06 3.41588725e-06 8.70962802e-04 5.04481897e-04\n",
      "  1.77379352e-05 1.29374243e-07 1.84678822e-06 5.10537138e-05\n",
      "  1.18784478e-03 5.93017057e-06 1.09333676e-04 4.98796408e-06\n",
      "  5.68812311e-06 5.72829485e-05 3.01437490e-06 2.65265608e-05\n",
      "  1.43911493e-07 3.45977860e-05 8.17236211e-03 5.11597500e-06\n",
      "  3.12719010e-02 4.22359677e-04 1.47018931e-04 3.38189139e-08\n",
      "  2.33331576e-07 3.69145512e-03 4.00900490e-06 3.75217176e-03\n",
      "  3.68983747e-05 1.68023194e-04 1.11426516e-06 1.75937661e-04\n",
      "  6.78000579e-05 2.58542685e-04 1.65581896e-05 3.82908866e-07\n",
      "  6.24218455e-06 4.28404292e-07 9.07516878e-05 2.31148588e-04\n",
      "  2.88345525e-08 1.40634228e-07 3.63013987e-06 2.08013674e-07\n",
      "  4.45079559e-06 1.49312200e-06 6.63655271e-07 1.05114104e-02\n",
      "  1.20109916e-02 1.11967859e-06 1.35316368e-04 5.80756750e-05\n",
      "  4.85371675e-05 8.20766945e-06 1.54587511e-07 1.71739903e-05\n",
      "  9.52877087e-07 8.79690342e-04 5.32731201e-06 1.12752088e-04\n",
      "  3.80522124e-06 1.24781844e-04 3.13667872e-04 3.00118445e-05\n",
      "  2.13700569e-05 3.89812584e-07 1.30529024e-05 4.02087055e-04\n",
      "  1.63749919e-05 6.46317767e-06 1.31066227e-02 2.74294522e-03\n",
      "  1.64151182e-08 2.16337558e-05 1.19147645e-02 2.06361346e-06\n",
      "  3.85466819e-06 5.64387051e-07 1.08573386e-06 3.40439256e-05\n",
      "  1.83727229e-06 3.33416597e-06 2.19613969e-04 6.44493193e-05\n",
      "  2.08191923e-05 5.01663744e-05 6.23804284e-04 7.53060294e-06\n",
      "  2.04992318e-07 8.29096735e-02 7.81344534e-06 3.71488168e-05\n",
      "  2.42989554e-05 1.40884670e-03 1.39252745e-06 1.06683802e-02\n",
      "  1.34502217e-04 2.77554900e-05 1.54213072e-03 6.23538144e-05\n",
      "  5.80381857e-06 2.82647961e-04 1.09237326e-05 2.90471595e-03\n",
      "  1.45786004e-07 2.42381101e-03 1.66352692e-07 5.19605419e-06\n",
      "  5.18963361e-07 9.98116797e-04 1.47683813e-05 8.71267286e-04\n",
      "  1.72287400e-06 7.24358472e-07 2.32652110e-05 2.48299307e-06\n",
      "  3.69163367e-08 2.93074959e-06 2.95221053e-05 3.72132968e-06\n",
      "  5.43223742e-08 1.50904425e-05 5.82745179e-06 1.66752173e-07\n",
      "  1.87310452e-05 1.79254974e-04 8.32794569e-07 3.70872975e-03\n",
      "  6.91538517e-05 7.88282021e-04 1.09608788e-02 6.55733806e-04\n",
      "  1.80137882e-04 1.92768557e-03 3.91314552e-06 2.53099774e-04\n",
      "  1.83106097e-03 1.77763832e-06 2.51538063e-06 3.03349334e-05\n",
      "  5.07712073e-04 5.15625729e-08 1.09506427e-05 5.31752733e-07\n",
      "  4.49221290e-07 4.50246176e-03 5.67736570e-04 2.05255631e-07\n",
      "  2.88944393e-05 1.34116783e-06 1.12990938e-05 9.74237901e-06\n",
      "  2.97489987e-05 8.71407246e-05 1.64892390e-06 7.95433039e-07\n",
      "  2.30561841e-06 4.97393194e-06 3.64566731e-05 1.25316010e-05\n",
      "  9.85439122e-03 1.61585540e-05 3.05017056e-05 3.33136413e-05\n",
      "  2.33153310e-06 6.97074283e-05 4.81189782e-04 1.33774699e-06\n",
      "  9.14644188e-05 4.32598987e-04 6.04082402e-07 6.31292060e-04\n",
      "  5.31610276e-05 4.23604288e-05 1.01185371e-07 3.43513711e-05\n",
      "  1.78772520e-04 2.32619848e-02 2.68550739e-05 1.34239110e-06\n",
      "  7.02731086e-06 3.52794899e-07 8.10920847e-06 1.13576597e-07\n",
      "  9.71443485e-04 3.36283379e-09 1.55478156e-05 7.19481381e-03\n",
      "  1.16321848e-04 5.13404395e-08 9.56950098e-05 7.98464054e-04\n",
      "  1.52620692e-06 7.04124477e-06 5.42025555e-05 1.10441266e-04\n",
      "  2.05395463e-05 1.15769099e-05 1.10563235e-07 4.51817250e-05\n",
      "  5.48684466e-06 1.88058529e-08 1.03438860e-02 1.11170976e-07\n",
      "  2.30438643e-04 3.62153310e-06 9.09737764e-07 4.50163061e-05\n",
      "  2.64660400e-07 5.03468254e-05 5.45820285e-06 6.44976080e-06\n",
      "  2.89691855e-07 2.82423222e-04 1.32890855e-04 1.56863782e-04\n",
      "  9.68015138e-06 6.11797208e-03 3.10042378e-05 1.58840783e-06\n",
      "  1.08061038e-04 2.90906560e-02 4.17381671e-06 7.81934214e-05\n",
      "  1.16362398e-05 1.86453038e-03 5.21727896e-04 2.86368891e-06\n",
      "  1.02565307e-02 4.93184338e-09 8.29155056e-08 1.99450733e-06\n",
      "  2.35889852e-03 5.06179958e-06 1.31306369e-05 2.71892105e-03\n",
      "  1.13367802e-03 5.58920146e-06 2.51642678e-06 4.11446272e-05\n",
      "  1.53399713e-04 1.21381572e-05 1.18519574e-05 8.45628892e-06\n",
      "  9.68030508e-05 1.37505176e-05 1.44428941e-06 1.86313584e-03\n",
      "  9.16084133e-08 4.15079854e-03 2.24980671e-04 7.05640065e-04\n",
      "  3.17050115e-04 5.54971455e-04 9.02209431e-05 4.76088751e-08\n",
      "  4.46464173e-06 1.21322446e-05 2.16932858e-06 2.67872347e-05\n",
      "  9.46478976e-04 5.37507549e-05 7.85908851e-05 4.88054013e-07\n",
      "  1.98029625e-06 2.66986763e-06 6.83650933e-06 3.42842753e-07\n",
      "  7.57090629e-06 1.42634917e-05 2.70240071e-06 5.50872704e-04\n",
      "  5.48520984e-05 3.58298712e-05 2.07373523e-05 3.14780550e-06\n",
      "  4.59259581e-06 7.19457312e-05 6.70626790e-08 1.52368671e-06\n",
      "  8.22157541e-04 5.30928337e-05 4.12510848e-03 1.16613296e-06\n",
      "  2.32048951e-05 2.70613004e-04 2.70754972e-04 1.81222840e-05\n",
      "  5.76880935e-04 9.38351423e-06 1.98534417e-05 4.54304682e-05\n",
      "  1.55963411e-04 1.88615362e-04 1.57916790e-03 6.16367629e-07\n",
      "  1.41970741e-05 6.67446147e-06 6.81904930e-05 1.66658847e-05\n",
      "  9.66094667e-04 1.45280748e-04 1.39466056e-06 4.15660732e-04\n",
      "  5.11757040e-04 1.80934578e-07 9.40681566e-05 1.00871818e-02\n",
      "  7.41623126e-07 9.42372754e-02 2.21033176e-07 9.23879538e-03\n",
      "  1.10057602e-03 6.69475639e-07 5.33959167e-07 4.04229786e-06\n",
      "  3.65553387e-05 2.48890919e-05 1.07406778e-02 2.61758978e-04\n",
      "  3.19968962e-07 3.02258904e-05 9.07473615e-04 2.88441707e-03\n",
      "  1.13793062e-02 4.90746118e-07 3.97584372e-04 4.33740615e-06\n",
      "  1.32355772e-05 9.51006004e-05 6.16196124e-03 5.48583316e-03\n",
      "  8.03530565e-05 2.27748733e-05 6.79421413e-04 1.47629034e-05\n",
      "  2.07681651e-07 5.08476747e-04 1.67479113e-01 1.98646361e-04\n",
      "  2.62927861e-05 6.67138829e-06 3.54615963e-06 7.02676916e-05\n",
      "  1.97615795e-04 1.59114290e-06 5.26746874e-07 7.75184981e-06\n",
      "  2.75876516e-07 2.14248448e-05 8.21834151e-03 3.02772480e-03\n",
      "  9.06468904e-06 2.58992277e-05 5.00971964e-07 5.11039863e-04\n",
      "  2.96028384e-06 1.46639250e-05 6.34229000e-05 1.53053028e-04\n",
      "  1.88244314e-07 5.14467217e-07 2.17541742e-06 6.31846051e-05\n",
      "  8.31250418e-07 1.43557017e-07 5.30050276e-03 1.38100982e-03\n",
      "  9.23046435e-04 3.72792783e-05 2.20364382e-06 3.02829048e-05\n",
      "  7.02475461e-07 9.17098077e-06 1.25264910e-06 1.92457192e-05\n",
      "  1.38092073e-05 2.27017517e-05 9.98156378e-04 6.06544461e-07\n",
      "  5.17459004e-04 3.18166826e-06 2.50265948e-05 9.06751302e-05\n",
      "  4.02484164e-02 2.41836794e-02 8.07468552e-07 1.02146237e-06\n",
      "  2.65717856e-04 7.53667427e-06 1.92193534e-06 2.00098802e-05\n",
      "  3.12208809e-04 3.97824067e-07 3.78693978e-04 9.18038495e-05\n",
      "  7.57777229e-07 3.56375813e-06 3.54427971e-06 9.86044062e-04\n",
      "  1.42663066e-05 6.42822270e-05 1.94059074e-04 1.46547858e-08\n",
      "  3.88727858e-05 6.12227552e-07 2.60021588e-05 2.66651128e-04\n",
      "  4.58156364e-03 6.49430558e-06 8.23343089e-06 4.30708241e-07\n",
      "  1.45371869e-05 1.56963893e-06 4.55775807e-05 8.51441473e-06\n",
      "  1.54195339e-04 1.16402898e-05 1.74719968e-03 1.88385980e-04\n",
      "  4.38319912e-05 1.60363852e-05 1.35965424e-03 8.37097502e-07\n",
      "  4.04331922e-06 2.16898243e-05 6.59391691e-04 2.95202739e-07\n",
      "  2.63048339e-08 3.10915971e-06 2.19644335e-06 2.54224524e-05\n",
      "  2.78238952e-03 2.73740618e-04 1.79914859e-04 1.37957022e-05\n",
      "  6.07227157e-05 1.18299769e-02 1.05105464e-04 1.11871223e-05\n",
      "  3.52329403e-06 3.67086983e-07 6.44672691e-05 6.68902294e-06\n",
      "  1.30302433e-04 3.80473706e-04 1.57724367e-06 3.46968118e-05\n",
      "  2.02884665e-04 1.11001953e-06 5.44374143e-06 3.85185522e-05\n",
      "  1.26218242e-06 1.12688886e-05 4.08174657e-07 8.67077460e-07\n",
      "  8.93464684e-02 3.48373123e-06 1.00526318e-04 1.79096151e-05\n",
      "  6.21089130e-04 1.25668815e-03 4.50083055e-02 7.85586622e-07\n",
      "  3.01107775e-07 3.15715238e-06 2.51069761e-08 7.92050070e-09\n",
      "  4.75910127e-07 1.09062232e-04 2.81310326e-06 1.48679726e-06\n",
      "  1.76938528e-07 1.44930567e-07 6.14053135e-07 9.03072760e-06\n",
      "  1.18236380e-06 3.19272613e-06 1.12364830e-06 3.86756170e-07\n",
      "  3.25745646e-07 3.68550950e-08 1.33651645e-06 5.46672527e-06\n",
      "  2.57602210e-07 9.47329966e-07 1.76163695e-07 1.00782427e-05\n",
      "  8.20330752e-05 7.16946670e-06 3.14316479e-04 3.17515915e-05\n",
      "  4.40255974e-08 4.54131168e-06 2.46936281e-04 3.46371394e-07\n",
      "  2.31915308e-07 6.42351324e-06 6.18699551e-06 4.56338540e-07\n",
      "  2.53433427e-07 4.48131232e-06 4.52146696e-06 2.29741062e-07\n",
      "  2.95363702e-06 6.04929824e-07 4.73920751e-04 2.31211307e-05\n",
      "  7.85268639e-06 1.73846763e-06 2.45533158e-08 8.43939924e-05\n",
      "  9.53750146e-08 8.70391759e-08 1.15454037e-08 8.95636163e-07\n",
      "  7.05301844e-08 5.56478426e-06 3.85188505e-05 3.76212439e-09\n",
      "  1.64181316e-07 3.72737850e-06 5.77415847e-07 3.19838989e-07\n",
      "  5.98501492e-06 1.88405807e-07 1.49186228e-08 1.56798138e-04\n",
      "  1.55888529e-07 2.31613490e-06 5.93933964e-06 1.59667457e-06\n",
      "  6.45521322e-06 1.66421312e-08 4.30472141e-07 6.33709263e-08\n",
      "  4.30301945e-08 5.37575715e-07 8.18353074e-05 6.45275431e-05]]\n"
     ]
    }
   ],
   "source": [
    "features = model.predict(x)\n",
    "print('\\nFeature Shape:\\n',features.shape)\n",
    "print('\\nFeatures:\\n',features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6537df83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tf-slim in c:\\users\\hp\\anaconda3\\envs\\anaconda\\lib\\site-packages (1.1.0)\n",
      "Requirement already satisfied: absl-py>=0.2.2 in c:\\users\\hp\\anaconda3\\envs\\anaconda\\lib\\site-packages (from tf-slim) (0.15.0)\n",
      "Requirement already satisfied: six in c:\\users\\hp\\anaconda3\\envs\\anaconda\\lib\\site-packages (from absl-py>=0.2.2->tf-slim) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tf-slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ca2a210",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mp\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tf_slim as slim\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6704a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Warning: Setting shuffle_files=True because split=TRAIN and shuffle_files=None. This behavior will be deprecated on 2019-08-06, at which point shuffle_files=False will be the default for all splits.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "mnist = tfds.load(name='mnist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2211a50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad9a6c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Warning: Setting shuffle_files=True because split=TRAIN and shuffle_files=None. This behavior will be deprecated on 2019-08-06, at which point shuffle_files=False will be the default for all splits.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "MNIST_data = tfds.load(name = \"mnist\")\n",
    "train, test = MNIST_data['train'] , MNIST_data['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fed3fbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "fashion_mnist = keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce06bfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tensorflow.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046a799d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
